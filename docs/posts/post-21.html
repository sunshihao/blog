<!DOCTYPE html><html class=" m-0 h-full p-0 font-sans antialiased" lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/docs/_next/static/css/8cd2eb158671e11e.css" data-precedence="next"/><link rel="stylesheet" href="/docs/_next/static/css/cc5160e2067b0cef.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/docs/_next/static/chunks/webpack-583a4211ac78a2fe.js"/><script src="/docs/_next/static/chunks/f064a1f5-a0f684639c5e404a.js" async=""></script><script src="/docs/_next/static/chunks/904-8193403601d33346.js" async=""></script><script src="/docs/_next/static/chunks/main-app-7d4b4602e3445646.js" async=""></script><script src="/docs/_next/static/chunks/779-ad4ead70309b9a20.js" async=""></script><script src="/docs/_next/static/chunks/739-1be71c4fce382004.js" async=""></script><script src="/docs/_next/static/chunks/138-7f27ef5cd2caf4b4.js" async=""></script><script src="/docs/_next/static/chunks/857-68a2fd358cb70760.js" async=""></script><script src="/docs/_next/static/chunks/594-71c3251836d38f7c.js" async=""></script><script src="/docs/_next/static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js" async=""></script><script src="/docs/_next/static/chunks/531-f976d425ce9a81a1.js" async=""></script><script src="/docs/_next/static/chunks/103-1875d9378f90876a.js" async=""></script><script src="/docs/_next/static/chunks/868-9c31f7c0009643d5.js" async=""></script><script src="/docs/_next/static/chunks/app/(app)/layout-66a850f3e6447c7d.js" async=""></script><script src="/docs/_next/static/chunks/245-4d9cc7d916e46c69.js" async=""></script><script src="/docs/_next/static/chunks/app/layout-d7953313cc6bdbf6.js" async=""></script><script src="/docs/_next/static/chunks/app/not-found-8b889a2f44e80cbe.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=123" as="script"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000212"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fafafa"/><title>LLM RAG （大语言模型检索增强生成技术）的前世今生 | William Sun</title><meta name="description" content="LLM RAG （大语言模型检索增强生成技术）的前世今生 - William Sun"/><link rel="manifest" href="/site.webmanifest" crossorigin="use-credentials"/><meta name="keywords" content="AI,LLM,RAG"/><meta name="baidu-site-verification" content="codeva-7AmpPWgzQY"/><meta name="google-site-verification" content="TTbfOvWmLj0icfk0BQNUZB3crwReji82Q_vRdnZFFAc"/><link rel="canonical" href="https://dhc.ink/posts/post-21"/><link rel="alternate" type="application/rss+xml" title="RSS 订阅" href="https://luckysnail.cn/rss"/><meta property="og:title" content="LLM RAG （大语言模型检索增强生成技术）的前世今生"/><meta property="og:description" content="LLM RAG （大语言模型检索增强生成技术）的前世今生 - William Sun"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@haozhan05554957"/><meta name="twitter:title" content="William Sunblog | 前端 | 开发者"/><meta name="twitter:description" content="我是William Sun，一名充满热情的前端开发工程师。我热衷于探索和体验最新技术，特别是人工智能（AI），并在日常工作中去使用它们，来提升我的工作效率。我的目标是积极参与开源社区，为开源项目贡献自己的力量。正如我的名字，我相信越努力，越幸运"/><meta name="twitter:image" content="https://luckysnail.cn/og.png"/><link rel="icon" href="/docs/favicon.ico" type="image/x-icon" sizes="32x32"/><link rel="icon" href="/docs/icon.jpg?021a5ddd40907a91" type="image/jpeg" sizes="256x256"/><link rel="apple-touch-icon" href="/docs/apple-icon.jpg?58f0c05bf91c4519" type="image/jpeg" sizes="1022x1023"/><script src="/docs/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="z-[-1] absolute bottom-0 left-0 right-0 top-0 bg-[linear-gradient(to_right,#4f4f4f2e_1px,transparent_1px),linear-gradient(to_bottom,#4f4f4f2e_1px,transparent_1px)] bg-[size:14px_24px] [mask-image:radial-gradient(ellipse_80%_50%_at_50%_0%,#000_70%,transparent_110%)]"></div><div class="fixed inset-0 flex justify-center sm:px-8"><div class="flex w-full max-w-7xl lg:px-8"><div class="opacity-95 w-full bg-zinc-50/90 ring-1 ring-zinc-100 dark:bg-zinc-900/80 dark:ring-zinc-400/20"></div></div></div><div class="relative text-zinc-800 dark:text-zinc-200"><header class="pointer-events-none relative z-50 mb-[var(--header-mb,0px)] flex flex-col h-[var(--header-height,64px)]"><div class="top-0 z-10 h-16 pt-6" style="position:var(--header-position)"><div class="sm:px-8 top-[var(--header-top,theme(spacing.6))] w-full" style="position:var(--header-inner-position)"><div class="mx-auto max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="relative flex gap-4"><div class="flex flex-1" style="opacity:0;transform:translateY(15px)"><div><div class="h-10 w-10 rounded-full bg-white/90 p-0.5 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur dark:bg-zinc-800/90 dark:ring-white/10"><a aria-label="主页" class="pointer-events-auto" href="/docs"><img alt="" loading="lazy" width="256" height="256" decoding="async" data-nimg="1" class="rounded-full bg-zinc-100 object-cover dark:bg-zinc-800 h-9 w-9" style="color:transparent" src="/docs/_next/static/media/logo.d3f4655a.webp"/></a></div></div></div><div class="flex flex-1 justify-end md:justify-center"><button class="group flex items-center rounded-full bg-gradient-to-b from-zinc-50/20 to-white/80 px-4 py-2 text-sm font-medium text-zinc-800 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur-md focus:outline-none focus-visible:ring-2 dark:from-zinc-900/30 dark:to-zinc-800/80 dark:text-zinc-200 dark:ring-white/10 dark:hover:ring-white/20 dark:focus-visible:ring-yellow-500/80 pointer-events-auto relative z-50 md:hidden" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3abnqra:" data-state="closed">前往<svg viewBox="0 0 8 6" aria-hidden="true" class="ml-3 h-auto w-2 stroke-zinc-500 group-hover:stroke-zinc-700 dark:group-hover:stroke-zinc-400"><path d="M1.75 1.75 4 4.25l2.25-2.5" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><nav class="group rounded-full bg-gradient-to-b from-zinc-50/70 to-white/90 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur-md dark:from-zinc-900/70 dark:to-zinc-800/90 dark:ring-zinc-100/10 [--spotlight-color:rgb(236_252_203_/_0.6)] dark:[--spotlight-color:rgb(217_249_157_/_0.07)] pointer-events-auto relative z-50 hidden md:block"><div class="pointer-events-none absolute -inset-px rounded-full opacity-0 transition-opacity duration-500 group-hover:opacity-100" aria-hidden="true" style="background:radial-gradient(0px circle at 0px 0px, var(--spotlight-color) 0%, transparent 65%)"></div><ul class="flex bg-transparent px-3 text-sm font-medium text-zinc-800 dark:text-zinc-200 "><li class="relative block whitespace-nowrap px-3 py-2 transition hover:text-violet-500 dark:hover:text-violet-400"><a target="_self" href="/docs">首页</a></li><li class="relative block whitespace-nowrap px-3 py-2 transition hover:text-violet-500 dark:hover:text-violet-400"><a target="_self" href="/docs/posts">博客</a></li><li class="relative block whitespace-nowrap px-3 py-2 transition hover:text-violet-500 dark:hover:text-violet-400"><a target="_self" href="/docs/about">关于我</a></li></ul></nav></div><div class="flex justify-end gap-3 md:flex-1" style="opacity:0;transform:translateY(-20px) scale(0.95)"><div class="pointer-events-auto"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div></div></div></div></div></div></div></div></header><main><!--$--><div class="sm:px-8 mt-10 lg:mt-16"><div class="mx-auto max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12 !px-0"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="w-full md:flex md:justify-between xl:relative gap-1"><aside class="hidden w-[160px] shrink-0 lg:block"><div class="sticky top-2 pt-16"><div class="toc-container"><h2 class="text-lg font-semibold mb-4">目录</h2><ul class="js-toc group pointer-events-auto flex flex-col space-y-2 text-zinc-500" style="opacity:0"></ul></div></div></aside><div class="max-w-4xl md:flex-1 md:shrink-0 "><a class="group mb-8 flex h-10 w-10 items-center justify-center bg-white dark:border dark:border-zinc-700/50 dark:bg-zinc-800 dark:ring-0 dark:hover:border-zinc-700 lg:absolute lg:-left-5 lg:-mt-2 lg:mb-0 xl:-top-1.5 xl:left-0 xl:mt-0 group rounded-full bg-gradient-to-b from-zinc-50/50 to-white/90 px-3 py-2 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur transition dark:from-zinc-900/50 dark:to-zinc-800/90 dark:ring-white/10 dark:hover:ring-white/20" aria-label="返回博客页面" href="/docs/posts"><svg width="1em" height="1em" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 stroke-zinc-500 transition group-hover:stroke-zinc-700 dark:stroke-zinc-500 dark:group-hover:stroke-zinc-400"><path d="M8.03089 4C6.57669 5.05865 5.2706 6.29537 4.14485 7.67887C4.04828 7.79755 4 7.94044 4 8.08333M8.03089 12.1667C6.57669 11.108 5.2706 9.8713 4.14485 8.4878C4.04828 8.36912 4 8.22623 4 8.08333M4 8.08333H14.963C17.7448 8.08333 20 10.3033 20 13.0417C20 15.7801 17.7448 18 14.963 18H12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></a><article data-postid="data/blog/post-21.mdx" class="rich-text-viewer prose px-4"><div class="mb-8 text-center"><h1 class="text-3xl font-bold">LLM RAG （大语言模型检索增强生成技术）的前世今生</h1><div class="flex justify-center rounded-md  h-5 items-center space-x-4 text-sm"><time dateTime="2024-10-08T14:53:54.000Z" class="mb-1 text-xs text-gray-600">2024-10-08</time><div data-orientation="vertical" role="none" class="shrink-0 bg-border h-full w-[1px]"></div><span class="mb-1 text-xs text-gray-600 flex items-center"><svg width="1em" height="1em" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="mr-2"><path d="M10.1912 12.5508C10.3071 12.1942 10.3071 11.8058 10.1912 11.4492C9.22165 8.46673 4.40272 8.00546 4.01443 4.48436C3.93458 3.76031 4.18955 3.04013 4.69671 2.55723C5.28193 2 6.62415 2 9.30861 2H14.6914C17.3759 2 18.7181 2 19.3033 2.55723C19.8104 3.04013 20.0654 3.76031 19.9856 4.48436C19.5973 8.00546 14.7784 8.46673 13.8088 11.4492C13.6929 11.8058 13.6929 12.1942 13.8088 12.5508C14.7784 15.5333 19.5973 15.9945 19.9856 19.5156C20.0654 20.2397 19.8104 20.9599 19.3033 21.4428C18.7181 22 17.3758 22 14.6914 22L9.3086 22C6.62415 22 5.28192 22 4.69671 21.4428C4.18955 20.9599 3.93458 20.2397 4.01442 19.5156C4.40272 15.9945 9.22164 15.5333 10.1912 12.5508Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg> <!-- -->6<!-- --> 分钟</span></div><div class="flex w-full justify-center gap-2 mt-2"><span class="inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800">AI</span><span class="inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800">LLM</span><span class="inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800">RAG</span></div></div><div class="js-toc-content"><h2 id="什么是-llm-rag-"><a class="anchor" href="#什么是-llm-rag-">什么是 LLM RAG ？</a></h2>
<p>LLM：Large Language Model （大型语言模型）</p>
<p>RAG：Retrieval-Augmented Generation （检索增强生成）</p>
<p>大语言模型的检索增强生成技术是一项通过结合外部知识库来<strong>优化</strong>大型语言模型的<strong>输出</strong>。这种技术的核心思想是从外部数据库中检索相关的信息，并将其与用户的查询一起输入到生成模块中，以生成更准确、更相关、更实时的响应回复</p>
<h2 id="产生背景"><a class="anchor" href="#产生背景">产生背景</a></h2>
<p>其实 RAG 技术在 2020 年就被提出， Facebook 的一篇论文：《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》 中首次引入了 RAG 的概念，这篇论文要解决的一个问题非常简单：如何让语言模型使用外部知识（external knowledge）进行生成。通常，预训练模型的知识存储在参数中，这就导致了模型不知道训练集之外的知识（例如搜索数据、行业的知识）。之前的做法是有新的知识就再重新在预训练的模型上进行<strong>微调</strong>。但是这样有两个问题：</p>
<ol>
<li>每次有新的知识后都需要进行<strong>微调</strong></li>
<li>训练模型的成本是很高的</li>
</ol>
<p>于是就有了 RAG，它利用预训练模型能够学习理解新的知识的能力，通过在 prompt 输入需要的新知识来实现更加可靠的回复，最后我们来看一下 LLM 目前的问题，</p>
<p></p>
<p>以上来源：<a href="https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md">https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md</a></p>
<h2 id="rag-系统组成和工作原理"><a class="anchor" href="#rag-系统组成和工作原理">RAG 系统组成和工作原理</a></h2>
<p>一个最小的 RAG 系统就是由 3 个部分组成的：</p>
<ol>
<li>语言模型</li>
<li>模型所需要的外部知识集合（以 vector 的形式存储）</li>
<li>当前场景下需要的外部知识</li>
</ol>
<p></p>
<p>上图是 RAG 系统的组成图，简单介绍：</p>
<ol>
<li>输入查询： 图的左侧显示了三种不同类型的输入查询：<!-- -->
<ul>
<li>问答任务：例如&quot;定义&#x27;中耳&#x27;&quot;</li>
<li>事实验证：例如&quot;巴拉克·奥巴马出生于夏威夷&quot;</li>
<li>Jeopardy（反向问答）问题生成：例如&quot;神曲&quot;，AI 来给出对应的问题</li>
</ul>
</li>
<li>查询编码器（Query Encoder）： 将输入查询编码为向量表示q(x)。</li>
<li>检索器pη（Retriever）： 这是一个非参数化模型，使用最大内积搜索（MIPS）在文档索引中查找与查询相关的文档。</li>
<li>文档索引d(z)： 存储了预先编码的文档向量（z1, z2, z3, z4等）。</li>
<li>生成器pθ（Generator）： 这是一个参数化模型，基于检索到的文档生成最终答案。</li>
<li>边缘化（Marginalize）： 对不同文档的seq2seq预测进行边缘化处理，得到最终输出。</li>
<li>输出： 根据任务类型生成不同的输出：<!-- -->
<ul>
<li>问答：生成答案，如&quot;中耳包括鼓室和三块听小骨&quot;</li>
<li>事实验证：生成标签，如&quot;支持&quot;</li>
<li>问题生成：生成问题，如&quot;这部14世纪的作品分为3个部分：&#x27;地狱&#x27;、&#x27;炼狱&#x27;和&#x27;天堂&#x27;&quot;</li>
</ul>
</li>
<li>端到端反向传播： 整个过程通过q和pθ进行端到端的反向传播，以优化模型性能。</li>
<li>方法概述： 该方法结合了预训练的检索器（查询编码器+文档索引）和预训练的seq2seq模型（生成器），并进行端到端的微调。对于查询x，使用MIPS找到top-K相关文档zi。在最终预测y时，将z视为潜在变量，并对不同文档的seq2seq预测进行边缘化。</li>
</ol>
<p>这种方法的优势在于它能够处理多种 NLP（Natural Language Processing 也就是 自然语言处理） 任务，并通过结合检索和生成模型来提高性能。通过端到端的训练，系统可以学习更好地协调检索和生成过程，从而产生更准确的结果。</p>
<p>RAG 系统的工作流程如下：</p>
<p></p>
<p>我们快速和宏观的看一下如何打造一个 RAG chat bot 的全流程：</p>
<ol>
<li>加载数据</li>
</ol>
<p>在真实项目，可能数据源的格式多种，例如 pdf、code、现存数据库、云数据库等等，我们需要将这些数据都加载进来，一般使用向量数据库</p>
<ol start="2">
<li>切分数据</li>
</ol>
<p>模型可接受的数据是有限的，这时候我们就需要把数据切分，但是数据源的多种多样和自然语言的特点，事实上切分函数的选择和参数的设定是非常难以控制的。理论上我们是希望每个文档块都是语意相关，并且相互独立的。</p>
<ol start="3">
<li>嵌入</li>
</ol>
<p>文本转为向量的过程，然后通过相似度匹配，来检索出我们想要的数据，同时解决了内容太大的问题</p>
<ol start="4">
<li>检索数据</li>
</ol>
<p>把问题转为向量，和向量数据库中向量进行检索得到想要的结果</p>
<p>这里还可以通过传统的关系形数据库 + Elasticsearch 来进行数据检索</p>
<ol start="5">
<li>增强 prompt</li>
</ol>
<p>其实上面所有做的都是为增强 prompt，我们对检索的信息 + 用户提问进行整合得到增强的 prompt ，提交给 LLM</p>
<ol start="6">
<li>生成</li>
</ol>
<p>把增强的 prompt 传递给生成结果模型，来生成答案</p>
<h2 id="总结"><a class="anchor" href="#总结">总结</a></h2>
<p>有两个通俗理解 RAG 作用的方式</p>
<ol>
<li>RAG 是给 LLM 开外挂</li>
<li>LLM 充当会思考的大脑角色，RAG 是获取相关知识的角色，通过 RAG 得到的知识集合，然后通过 LLM 来思考整理生成结果</li>
</ol>
<h2 id="参考"><a class="anchor" href="#参考">参考</a></h2>
<ol>
<li>devv 如何构建高效 RAG 系统：<a href="https://x.com/forrestzh_/status/1731478506465636749?s=20">https://x.com/forrestzh_/status/1731478506465636749</a></li>
<li>RAG 简介：<a href="https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md">https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md</a></li>
</ol>
<hr/>
<p>此文自动发布于：<a href="https://github.com/coderPerseus/blog/issues/21" target="_blank">github issues</a></p></div></article><div class="flex px-4 justify-between mt-8"><a class="inline-flex items-center justify-center rounded-md px-4 py-2 text-sm font-medium text-violet-500 dark:text-violet-300 shadow-sm hover:bg-violet-200 dark:hover:bg-violet-500 focus:outline-none focus:ring-2 focus:ring-violet-600 focus:ring-offset-2" href="/docs/posts/post-22">webStorm 快速入门上手开发</a><a class="inline-flex items-center justify-center rounded-md px-4 py-2 text-sm font-medium text-violet-500 dark:text-violet-300 shadow-sm hover:bg-violet-200 dark:hover:bg-violet-500 focus:outline-none focus:ring-2 focus:ring-violet-600 focus:ring-offset-2" href="/docs/posts/post-20">DOM元素导出图片与PDF：多种方案对比...</a></div></div></div></div></div></div></div><!--/$--></main><!--$--><footer class="mt-32"><div class="sm:px-8"><div class="mx-auto max-w-7xl lg:px-8"><div class="border-t border-zinc-100 pb-16 pt-10 dark:border-zinc-700/40"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="flex flex-col items-center justify-between gap-6 sm:flex-row"><p class="text-sm text-zinc-500/80 dark:text-zinc-400/80">© <!-- -->2025<!-- --> <!-- -->William Sun<!-- --> 网站已开源：<a class="inline-flex place-items-baseline items-baseline gap-0.5 pr-0.5 text-[0.95em] leading-none font-semibold text-zinc-800 hover:underline dark:text-zinc-100" rel="noopener noreferrer" target="_blank" href="https://github.com/coderPerseus/blog"><span class="mr-px inline-flex translate-y-0.5 dark:invert"><img alt="" aria-hidden="true" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" class="inline h-4 w-4 rounded" style="color:transparent" src="/docs/_next/static/media/github.ee3e4451.png"/></span>William Sun<svg width="0.95em" height="0.95em" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="inline-block translate-y-0.5" aria-hidden="true"><path d="M20 13.5001C20 14.8946 20 15.5919 19.8618 16.1673C19.4229 17.9956 17.9955 19.423 16.1672 19.8619C15.5918 20.0001 14.8945 20.0001 13.5 20.0001H12C9.19974 20.0001 7.79961 20.0001 6.73005 19.4551C5.78924 18.9758 5.02433 18.2109 4.54497 17.2701C4 16.2005 4 14.8004 4 12.0001V11.5001C4 9.17035 4 8.0055 4.3806 7.08664C4.88807 5.8615 5.86144 4.88813 7.08658 4.38066C7.86344 4.05888 8.81614 4.00915 10.5 4.00146M19.7597 9.45455C20.0221 7.8217 20.0697 6.16984 19.9019 4.54138C19.8898 4.42328 19.838 4.31854 19.7597 4.24027M19.7597 4.24027C19.6815 4.16201 19.5767 4.11023 19.4586 4.09806C17.8302 3.93025 16.1783 3.97792 14.5455 4.24027M19.7597 4.24027L10 14" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></a></p><nav class="flex gap-6 text-sm font-medium text-zinc-800 dark:text-zinc-200"><a class="transition hover:text-violet-500 dark:hover:text-violet-400" href="/docs">首页</a><a class="transition hover:text-violet-500 dark:hover:text-violet-400" href="/docs/posts">博客</a><a class="transition hover:text-violet-500 dark:hover:text-violet-400" href="/docs/about">关于我</a></nav></div></div></div><div class="relative px-4 sm:px-8 lg:px-12 mt-6"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="flex flex-col items-center justify-start gap-2 sm:flex-row">欢迎 👏🏻 你的访问</div></div></div><div class="flex justify-center p-6 flex-col sm:flex-row"><a target="_blank" class="text-blue-600 flex justify-center items-center" href="https://beian.miit.gov.cn/"><img alt="备案" loading="lazy" width="18" height="18" decoding="async" data-nimg="1" class="mr-1 " style="color:transparent" src="/blog/police.png"/>辽公网安备21021202000334号</a><a target="_blank" class="text-blue-600 pl-6 flex justify-center items-center" href="https://beian.miit.gov.cn/">辽ICP备2021012379号-1</a></div></div></div></div></footer><!--/$--></div><script src="/docs/_next/static/chunks/webpack-583a4211ac78a2fe.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/docs/_next/static/css/8cd2eb158671e11e.css\",\"style\"]\n2:HL[\"/docs/_next/static/css/cc5160e2067b0cef.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[1439,[],\"\"]\n5:I[7401,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"594\",\"static/chunks/594-71c3251836d38f7c.js\",\"878\",\"static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js\"],\"default\"]\n6:I[2219,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"594\",\"static/chunks/594-71c3251836d38f7c.js\",\"878\",\"static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js\"],\"\"]\n7:I[6814,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"594\",\"static/chunks/594-71c3251836d38f7c.js\",\"878\",\"static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js\"],\"Separator\"]\n8:I[8501,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"594\",\"static/chunks/594-71c3251836d38f7c.js\",\"878\",\"static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js\"],\"default\"]\n9:I[1473,[],\"\"]\nb:I[9658,[],\"\"]\nc:I[3205,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"531\",\"static/chunks/531-f976d425ce9a81a1.js\",\"103\",\"static/chunks/103-1875d9378f90876a.js\",\"868\",\"static/chunks/868-9c31f7c0009643d5.js\",\"814\",\"static/chunks/app/(app)/layout-66a850f3e6447c7d.js\"],\"GlobalBg\"]\nd:I[7726,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"531\",\"static/chunks/531-f976d425ce9a81a1.js\",\"103\",\"static/chunks/103-1875d9378f90876a.js\",\"868\",\"static/chunks/868-9c31f7c0009643d5.js\",\"814\",\"static/chunks/app/(app)/layout-66a850f3e6447c7d.js\"],\"Head"])</script><script>self.__next_f.push([1,"er\"]\ne:\"$Sreact.suspense\"\nf:I[4662,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"531\",\"static/chunks/531-f976d425ce9a81a1.js\",\"103\",\"static/chunks/103-1875d9378f90876a.js\",\"868\",\"static/chunks/868-9c31f7c0009643d5.js\",\"814\",\"static/chunks/app/(app)/layout-66a850f3e6447c7d.js\"],\"PeekabooLink\"]\n10:I[4543,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"138\",\"static/chunks/138-7f27ef5cd2caf4b4.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"594\",\"static/chunks/594-71c3251836d38f7c.js\",\"878\",\"static/chunks/app/(app)/posts/%5Bid%5D/page-6bb6cd9ad97d098b.js\"],\"Image\"]\n11:I[2962,[\"245\",\"static/chunks/245-4d9cc7d916e46c69.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"185\",\"static/chunks/app/layout-d7953313cc6bdbf6.js\"],\"default\"]\n12:I[7808,[\"245\",\"static/chunks/245-4d9cc7d916e46c69.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"185\",\"static/chunks/app/layout-d7953313cc6bdbf6.js\"],\"default\"]\n13:I[5433,[\"245\",\"static/chunks/245-4d9cc7d916e46c69.js\",\"857\",\"static/chunks/857-68a2fd358cb70760.js\",\"185\",\"static/chunks/app/layout-d7953313cc6bdbf6.js\"],\"ThemeProvider\"]\n14:I[3970,[\"779\",\"static/chunks/779-ad4ead70309b9a20.js\",\"739\",\"static/chunks/739-1be71c4fce382004.js\",\"160\",\"static/chunks/app/not-found-8b889a2f44e80cbe.js\"],\"default\"]\n16:I[2716,[],\"\"]\na:[\"id\",\"post-21\",\"d\"]\n17:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/docs/_next/static/css/8cd2eb158671e11e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"9zTx61biyYvfSRWm2Ulvt\",\"assetPrefix\":\"/docs\",\"initialCanonicalUrl\":\"/posts/post-21\",\"initialTree\":[\"\",{\"children\":[\"(app)\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"post-21\",\"d\"],{\"children\":[\"__PAGE__?{\\\"id\\\":\\\"post-21\\\"}\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(app)\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"post-21\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"div\",null,{\"className\":\"sm:px-8 mt-10 lg:mt-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative px-4 sm:px-8 lg:px-12 !px-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl lg:max-w-5xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-full md:flex md:justify-between xl:relative gap-1\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"hidden w-[160px] shrink-0 lg:block\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-2 pt-16\",\"children\":[\"$\",\"$L5\",null,{}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-4xl md:flex-1 md:shrink-0 \",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/posts\",\"className\":\"group mb-8 flex h-10 w-10 items-center justify-center bg-white dark:border dark:border-zinc-700/50 dark:bg-zinc-800 dark:ring-0 dark:hover:border-zinc-700 lg:absolute lg:-left-5 lg:-mt-2 lg:mb-0 xl:-top-1.5 xl:left-0 xl:mt-0 group rounded-full bg-gradient-to-b from-zinc-50/50 to-white/90 px-3 py-2 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur transition dark:from-zinc-900/50 dark:to-zinc-800/90 dark:ring-white/10 dark:hover:ring-white/20\",\"aria-label\":\"返回博客页面\",\"children\":[\"$\",\"svg\",null,{\"width\":\"1em\",\"height\":\"1em\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"h-8 w-8 stroke-zinc-500 transition group-hover:stroke-zinc-700 dark:stroke-zinc-500 dark:group-hover:stroke-zinc-400\",\"children\":[\"$\",\"path\",null,{\"d\":\"M8.03089 4C6.57669 5.05865 5.2706 6.29537 4.14485 7.67887C4.04828 7.79755 4 7.94044 4 8.08333M8.03089 12.1667C6.57669 11.108 5.2706 9.8713 4.14485 8.4878C4.04828 8.36912 4 8.22623 4 8.08333M4 8.08333H14.963C17.7448 8.08333 20 10.3033 20 13.0417C20 15.7801 17.7448 18 14.963 18H12\",\"stroke\":\"currentColor\",\"strokeWidth\":\"2\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\"}]}]}],[\"$\",\"article\",null,{\"data-postid\":\"data/blog/post-21.mdx\",\"className\":\"rich-text-viewer prose px-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8 text-center\",\"children\":[\"$undefined\",[\"$\",\"h1\",null,{\"className\":\"text-3xl font-bold\",\"children\":\"LLM RAG （大语言模型检索增强生成技术）的前世今生\"}],[\"$\",\"div\",null,{\"className\":\"flex justify-center rounded-md  h-5 items-center space-x-4 text-sm\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2024-10-08T14:53:54.000Z\",\"className\":\"mb-1 text-xs text-gray-600\",\"children\":\"2024-10-08\"}],[\"$\",\"$L7\",null,{\"orientation\":\"vertical\"}],[\"$\",\"span\",null,{\"className\":\"mb-1 text-xs text-gray-600 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"width\":\"1em\",\"height\":\"1em\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"mr-2\",\"children\":[\"$\",\"path\",null,{\"d\":\"M10.1912 12.5508C10.3071 12.1942 10.3071 11.8058 10.1912 11.4492C9.22165 8.46673 4.40272 8.00546 4.01443 4.48436C3.93458 3.76031 4.18955 3.04013 4.69671 2.55723C5.28193 2 6.62415 2 9.30861 2H14.6914C17.3759 2 18.7181 2 19.3033 2.55723C19.8104 3.04013 20.0654 3.76031 19.9856 4.48436C19.5973 8.00546 14.7784 8.46673 13.8088 11.4492C13.6929 11.8058 13.6929 12.1942 13.8088 12.5508C14.7784 15.5333 19.5973 15.9945 19.9856 19.5156C20.0654 20.2397 19.8104 20.9599 19.3033 21.4428C18.7181 22 17.3758 22 14.6914 22L9.3086 22C6.62415 22 5.28192 22 4.69671 21.4428C4.18955 20.9599 3.93458 20.2397 4.01442 19.5156C4.40272 15.9945 9.22164 15.5333 10.1912 12.5508Z\",\"stroke\":\"currentColor\",\"strokeWidth\":\"2\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\"}]}],\" \",6,\" 分钟\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex w-full justify-center gap-2 mt-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800\",\"children\":\"AI\"}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800\",\"children\":\"LLM\"}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center px-2 h-5 rounded-md text-xs  bg-gray-300 text-gray-800\",\"children\":\"RAG\"}]]}],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"js-toc-content\",\"children\":[[\"$\",\"h2\",null,{\"id\":\"什么是-llm-rag-\",\"children\":[\"$\",\"a\",null,{\"className\":\"anchor\",\"href\":\"#什么是-llm-rag-\",\"children\":\"什么是 LLM RAG ？\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM：Large Language Model （大型语言模型）\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"RAG：Retrieval-Augmented Generation （检索增强生成）\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"大语言模型的检索增强生成技术是一项通过结合外部知识库来\",[\"$\",\"strong\",null,{\"children\":\"优化\"}],\"大型语言模型的\",[\"$\",\"strong\",null,{\"children\":\"输出\"}],\"。这种技术的核心思想是从外部数据库中检索相关的信息，并将其与用户的查询一起输入到生成模块中，以生成更准确、更相关、更实时的响应回复\"]}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"产生背景\",\"children\":[\"$\",\"a\",null,{\"className\":\"anchor\",\"href\":\"#产生背景\",\"children\":\"产生背景\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"其实 RAG 技术在 2020 年就被提出， Facebook 的一篇论文：《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》 中首次引入了 RAG 的概念，这篇论文要解决的一个问题非常简单：如何让语言模型使用外部知识（external knowledge）进行生成。通常，预训练模型的知识存储在参数中，这就导致了模型不知道训练集之外的知识（例如搜索数据、行业的知识）。之前的做法是有新的知识就再重新在预训练的模型上进行\",[\"$\",\"strong\",null,{\"children\":\"微调\"}],\"。但是这样有两个问题：\"]}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"每次有新的知识后都需要进行\",[\"$\",\"strong\",null,{\"children\":\"微调\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"训练模型的成本是很高的\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"于是就有了 RAG，它利用预训练模型能够学习理解新的知识的能力，通过在 prompt 输入需要的新知识来实现更加可靠的回复，最后我们来看一下 LLM 目前的问题，\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"$L8\",null,{\"src\":\"https://blog-1304565468.cos.ap-shanghai.myqcloud.com/work/1728353558736-1dcf2a98-dd73-4b9e-9b4c-188337a369b6.png\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"以上来源：\",[\"$\",\"a\",null,{\"href\":\"https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md\",\"children\":\"https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md\"}]]}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"rag-系统组成和工作原理\",\"children\":[\"$\",\"a\",null,{\"className\":\"anchor\",\"href\":\"#rag-系统组成和工作原理\",\"children\":\"RAG 系统组成和工作原理\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"一个最小的 RAG 系统就是由 3 个部分组成的：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"语言模型\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"模型所需要的外部知识集合（以 vector 的形式存储）\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"当前场景下需要的外部知识\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"$L8\",null,{\"src\":\"https://blog-1304565468.cos.ap-shanghai.myqcloud.com/work/1728353764729-bb5d2fff-01ef-42c3-912c-6dd5caf7970c.jpeg\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"上图是 RAG 系统的组成图，简单介绍：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"输入查询： 图的左侧显示了三种不同类型的输入查询：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"问答任务：例如\\\"定义'中耳'\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"事实验证：例如\\\"巴拉克·奥巴马出生于夏威夷\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Jeopardy（反向问答）问题生成：例如\\\"神曲\\\"，AI 来给出对应的问题\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"查询编码器（Query Encoder）： 将输入查询编码为向量表示q(x)。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"检索器pη（Retriever）： 这是一个非参数化模型，使用最大内积搜索（MIPS）在文档索引中查找与查询相关的文档。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"文档索引d(z)： 存储了预先编码的文档向量（z1, z2, z3, z4等）。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"生成器pθ（Generator）： 这是一个参数化模型，基于检索到的文档生成最终答案。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"边缘化（Marginalize）： 对不同文档的seq2seq预测进行边缘化处理，得到最终输出。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"输出： 根据任务类型生成不同的输出：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"问答：生成答案，如\\\"中耳包括鼓室和三块听小骨\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"事实验证：生成标签，如\\\"支持\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"问题生成：生成问题，如\\\"这部14世纪的作品分为3个部分：'地狱'、'炼狱'和'天堂'\\\"\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"端到端反向传播： 整个过程通过q和pθ进行端到端的反向传播，以优化模型性能。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"方法概述： 该方法结合了预训练的检索器（查询编码器+文档索引）和预训练的seq2seq模型（生成器），并进行端到端的微调。对于查询x，使用MIPS找到top-K相关文档zi。在最终预测y时，将z视为潜在变量，并对不同文档的seq2seq预测进行边缘化。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"这种方法的优势在于它能够处理多种 NLP（Natural Language Processing 也就是 自然语言处理） 任务，并通过结合检索和生成模型来提高性能。通过端到端的训练，系统可以学习更好地协调检索和生成过程，从而产生更准确的结果。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"RAG 系统的工作流程如下：\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"$L8\",null,{\"src\":\"https://github.com/datawhalechina/llm-universe/raw/main/figures/C1-2-RAG.png\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"我们快速和宏观的看一下如何打造一个 RAG chat bot 的全流程：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"加载数据\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"在真实项目，可能数据源的格式多种，例如 pdf、code、现存数据库、云数据库等等，我们需要将这些数据都加载进来，一般使用向量数据库\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"2\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"切分数据\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"模型可接受的数据是有限的，这时候我们就需要把数据切分，但是数据源的多种多样和自然语言的特点，事实上切分函数的选择和参数的设定是非常难以控制的。理论上我们是希望每个文档块都是语意相关，并且相互独立的。\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"3\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"嵌入\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"文本转为向量的过程，然后通过相似度匹配，来检索出我们想要的数据，同时解决了内容太大的问题\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"4\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"检索数据\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"把问题转为向量，和向量数据库中向量进行检索得到想要的结果\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"这里还可以通过传统的关系形数据库 + Elasticsearch 来进行数据检索\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"5\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"增强 prompt\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"其实上面所有做的都是为增强 prompt，我们对检索的信息 + 用户提问进行整合得到增强的 prompt ，提交给 LLM\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"6\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"生成\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"把增强的 prompt 传递给生成结果模型，来生成答案\"}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"总结\",\"children\":[\"$\",\"a\",null,{\"className\":\"anchor\",\"href\":\"#总结\",\"children\":\"总结\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"有两个通俗理解 RAG 作用的方式\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"RAG 是给 LLM 开外挂\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"LLM 充当会思考的大脑角色，RAG 是获取相关知识的角色，通过 RAG 得到的知识集合，然后通过 LLM 来思考整理生成结果\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"参考\",\"children\":[\"$\",\"a\",null,{\"className\":\"anchor\",\"href\":\"#参考\",\"children\":\"参考\"}]}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"devv 如何构建高效 RAG 系统：\",[\"$\",\"a\",null,{\"href\":\"https://x.com/forrestzh_/status/1731478506465636749?s=20\",\"children\":\"https://x.com/forrestzh_/status/1731478506465636749\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"RAG 简介：\",[\"$\",\"a\",null,{\"href\":\"https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md\",\"children\":\"https://github.com/datawhalechina/llm-universe/blob/main/docs/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%20RAG%20%E7%AE%80%E4%BB%8B.md\"}]]}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"此文自动发布于：\",[\"$\",\"a\",null,{\"href\":\"https://github.com/coderPerseus/blog/issues/21\",\"target\":\"_blank\",\"children\":\"github issues\"}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"flex px-4 justify-between mt-8\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/posts/post-22\",\"className\":\"inline-flex items-center justify-center rounded-md px-4 py-2 text-sm font-medium text-violet-500 dark:text-violet-300 shadow-sm hover:bg-violet-200 dark:hover:bg-violet-500 focus:outline-none focus:ring-2 focus:ring-violet-600 focus:ring-offset-2\",\"children\":\"webStorm 快速入门上手开发\"}],[\"$\",\"$L6\",null,{\"href\":\"/posts/post-20\",\"className\":\"inline-flex items-center justify-center rounded-md px-4 py-2 text-sm font-medium text-violet-500 dark:text-violet-300 shadow-sm hover:bg-violet-200 dark:hover:bg-violet-500 focus:outline-none focus:ring-2 focus:ring-violet-600 focus:ring-offset-2\",\"children\":\"DOM元素导出图片与PDF：多种方案对比...\"}]]}]]}]]}]}]}]}]}]],null],null]},[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(app)\",\"children\",\"posts\",\"children\",\"$a\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/docs/_next/static/css/cc5160e2067b0cef.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],[[\"$\",\"div\",null,{\"className\":\"sm:px-8 relative mt-16 min-h-screen lg:mt-32\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative px-4 sm:px-8 lg:px-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl lg:max-w-5xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"absolute inset-0 flex items-center justify-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-pulse text-5xl text-zinc-500/50\",\"children\":[\"$\",\"svg\",null,{\"width\":\"1em\",\"height\":\"1em\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[\"$\",\"path\",null,{\"d\":\"M16.5609 7.43931C15.7777 5.41156 14.0301 4 12 4C9.96987 4 8.22234 5.41156 7.43913 7.43931M16.5609 7.43931C19.7904 8.10251 22 9.44804 22 11C22 13.2091 17.5228 15 12 15C6.47715 15 2 13.2091 2 11C2 9.44804 4.20962 8.10251 7.43913 7.43931M16.5609 7.43931C16.94 8.42085 17.0719 9.49351 16.9638 10.5391C15.5011 10.8323 13.8065 11 12 11C10.1935 11 8.49887 10.8323 7.03622 10.5391C6.92815 9.49351 7.06001 8.42085 7.43913 7.43931M4 17L3 19M12 18V21M20 17L21 19\",\"stroke\":\"currentColor\",\"strokeWidth\":\"2\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\"}]}]}]}]}]}]}]}],[],[]]]},[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(app)\",\"children\",\"posts\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[[\"$\",\"$Lc\",null,{}],[\"$\",\"div\",null,{\"className\":\"fixed inset-0 flex justify-center sm:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex w-full max-w-7xl lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"opacity-95 w-full bg-zinc-50/90 ring-1 ring-zinc-100 dark:bg-zinc-900/80 dark:ring-zinc-400/20\"}]}]}],[\"$\",\"div\",null,{\"className\":\"relative text-zinc-800 dark:text-zinc-200\",\"children\":[[\"$\",\"$Ld\",null,{}],[\"$\",\"main\",null,{\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(app)\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]}],[\"$\",\"$e\",null,{\"children\":[\"$\",\"footer\",null,{\"className\":\"mt-32\",\"children\":[\"$\",\"div\",null,{\"className\":\"sm:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"border-t border-zinc-100 pb-16 pt-10 dark:border-zinc-700/40\",\"children\":[[\"$\",\"div\",null,{\"className\":\"relative px-4 sm:px-8 lg:px-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl lg:max-w-5xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-between gap-6 sm:flex-row\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-sm text-zinc-500/80 dark:text-zinc-400/80\",\"children\":[\"© \",2025,\" \",\"William Sun\",\" 网站已开源：\",[\"$\",\"$Lf\",null,{\"href\":\"https://github.com/coderPerseus/blog\",\"children\":\"William Sun\"}]]}],[\"$\",\"nav\",null,{\"className\":\"flex gap-6 text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/\",\"className\":\"transition hover:text-violet-500 dark:hover:text-violet-400\",\"children\":\"首页\"}],[\"$\",\"$L6\",null,{\"href\":\"/posts\",\"className\":\"transition hover:text-violet-500 dark:hover:text-violet-400\",\"children\":\"博客\"}],[\"$\",\"$L6\",null,{\"href\":\"/about\",\"className\":\"transition hover:text-violet-500 dark:hover:text-violet-400\",\"children\":\"关于我\"}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"relative px-4 sm:px-8 lg:px-12 mt-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl lg:max-w-5xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-start gap-2 sm:flex-row\",\"children\":\"欢迎 👏🏻 你的访问\"}]}]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center p-6 flex-col sm:flex-row\",\"children\":[[\"$\",\"$L6\",null,{\"target\":\"_blank\",\"href\":\"https://beian.miit.gov.cn/\",\"className\":\"text-blue-600 flex justify-center items-center\",\"children\":[[\"$\",\"$L10\",null,{\"unoptimized\":true,\"src\":\"/blog/police.png\",\"width\":18,\"height\":18,\"alt\":\"备案\",\"className\":\"mr-1 \"}],\"辽公网安备21021202000334号\"]}],[\"$\",\"$L6\",null,{\"target\":\"_blank\",\"href\":\"https://beian.miit.gov.cn/\",\"className\":\"text-blue-600 pl-6 flex justify-center items-center\",\"children\":\"辽ICP备2021012379号-1\"}]]}]]}]}]}]}]}]]}]],null],null]},[[\"$\",\"html\",null,{\"className\":\" m-0 h-full p-0 font-sans antialiased\",\"lang\":\"zh-CN\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"children\":[[\"$\",\"$L11\",null,{}],[\"$\",\"$L12\",null,{}],[\"$\",\"$L13\",null,{\"attribute\":\"class\",\"defaultTheme\":\"system\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$L14\",null,{}],\"notFoundStyles\":[],\"styles\":null}]}]]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$L15\"],\"globalErrorComponent\":\"$16\",\"missingSlots\":\"$W17\"}]]\n"])</script><script>self.__next_f.push([1,"15:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: dark)\",\"content\":\"#000212\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: light)\",\"content\":\"#fafafa\"}],[\"$\",\"meta\",\"3\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"4\",{\"children\":\"LLM RAG （大语言模型检索增强生成技术）的前世今生 | William Sun\"}],[\"$\",\"meta\",\"5\",{\"name\":\"description\",\"content\":\"LLM RAG （大语言模型检索增强生成技术）的前世今生 - William Sun\"}],[\"$\",\"link\",\"6\",{\"rel\":\"manifest\",\"href\":\"/site.webmanifest\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"7\",{\"name\":\"keywords\",\"content\":\"AI,LLM,RAG\"}],[\"$\",\"meta\",\"8\",{\"name\":\"baidu-site-verification\",\"content\":\"codeva-7AmpPWgzQY\"}],[\"$\",\"meta\",\"9\",{\"name\":\"google-site-verification\",\"content\":\"TTbfOvWmLj0icfk0BQNUZB3crwReji82Q_vRdnZFFAc\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://dhc.ink/posts/post-21\"}],[\"$\",\"link\",\"11\",{\"rel\":\"alternate\",\"type\":\"application/rss+xml\",\"title\":\"RSS 订阅\",\"href\":\"https://luckysnail.cn/rss\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"LLM RAG （大语言模型检索增强生成技术）的前世今生\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"LLM RAG （大语言模型检索增强生成技术）的前世今生 - William Sun\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:creator\",\"content\":\"@haozhan05554957\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:title\",\"content\":\"William Sunblog | 前端 | 开发者\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:description\",\"content\":\"我是William Sun，一名充满热情的前端开发工程师。我热衷于探索和体验最新技术，特别是人工智能（AI），并在日常工作中去使用它们，来提升我的工作效率。我的目标是积极参与开源社区，为开源项目贡献自己的力量。正如我的名字，我相信越努力，越幸运\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:image\",\"content\":\"https://luckysnail.cn/og.png\"}],[\"$\",\"link\",\"19\",{\"rel\":\"icon\",\"href\":\"/docs/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"32x32\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/docs/icon.jpg?021a5ddd40907a91\",\"type\":\"image/jpeg\",\"sizes\":\"256x256\"}],[\"$\",\"link\",\"21\",{\"rel\":\"apple-touch-icon\",\"href\":\"/docs/apple-icon.jpg?58f0c05bf91c4519\",\"type\":\"image/jpeg\",\"sizes\":\"1022x1023\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>